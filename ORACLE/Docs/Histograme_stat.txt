**********************************************************
The METHOD_OPT parameter in the GATHER_DICTIONARY_STATS
**********************************************************
In summary: 
METHOD_OPT parameter controls which columns get basic statistics as well as which columns get histograms,
sett this parameter in two parts.The method_opt argument within dbms_stats controls the following:

-The generation of histograms
-The creation of extended statistics  (Oracle 11g)
-The collection of "base" column statistics
*The METHOD_OPT parameter in the GATHER_DICTIONARY_STATS, GATHER_DATABASE_STATS, and GATHER_SCHEMA_STATS procedures only accepts 'FOR ALL [INDEXED|HIDDEN]columns' syntax. 
 No specific column names can be specified.

2-When used in the GATHER_TABLE_STATS procedure, the METHOD_OPT parameter can accept an additional argument in the form of ‘FOR columns …'.
Using this syntax allows you to control:

-which columns to gather basic statistics 
-which columns to gather histograms and the bucket size 
-which extended statistics to create

The METHOD_OPT parameter syntax is made up of multiple parts. The first two parts are mandatory and are broken down in the diagram below.

" FOR ALL [INDEXED|HIDDEN] COLUMNS SIZE [SIZE_CLAUSE/1-254/AUTO]"       1 means no histogram created 
-FOR ALL COLUMNS(HIDDEN INCLUDED)First part controls which columns will have base column statistics (min,max,NDV,number of nulls, etc) gathered on them.


FOR ALL INDEXED COLUMNS: limits base column gathering to only those columns that are included in an index. not recomanded
FOR ALL HIDDEN  COLUMNS: limits base column statistics gathering to only the virtual columns that have been created on a table. not recomanded 

The SIZE part of the METHOD_OPT syntax controls the creation of histograms and can have the following settings;
AUTO: means Oracle will automatically determines the columns that need histograms based on the column usage information (SYS.COL_USAGE$), and the presence of a data skew. 
Integer value[1,254]: Indicates histogram creation with at most x number of buckets.
To force histogram creation it is recommended that buckets Nb be left at 254. Note SIZE 1 means no histogram will be created.
REPEAT: ensures a histogram will only be created for any column that already has one.but will always keep the same number of bucket when regathering stats
SKEWONLY: automatically creates a histogram on any column that shows a skew in its data distribution.


Example 1 : only CUST_ID will have histograms (1 means 0 for the others)
-----------
BEGIN 
 dbms_stats.Gather_table_stats('SH', 'SALES', - 
 method_opt => 'FOR ALL COLUMNS SIZE 1 FOR COLUMNS SIZE 254 CUST_ID'); 
END; 
/


Example 2: Multiple columns' historgram Nbr 
-----------
BEGIN 
 dbms_stats.Gather_table_stats('SH', 'SALES',-
 method_opt => 'FOR COLUMNS SIZE 254 CUST_ID TIME_ID CHANNEL_ID PROMO_ID 
 QUANTITY_SOLD 2 AMOUNT_SOLD'); 
END; 
/

EXAMPLE 3 :  Extended statistics :encompasses two additional types of column statistics; column groups and expression statistics. 
----------
extended statistic on (PROD_ID and CUST_ID)
BEGIN
dbms_stats.Gather_table_stats('SH', 'SALES',
method_opt => 'FOR ALL COLUMNS SIZE 254 FOR COLUMNS SIZE 254(PROD_ID, CUST_ID)');
END;
/

OR 
Select  dbms_stats.create_extended_stats (NULL, 'SALES', '(PROD_ID,CUST_ID)') from dual;

EXAMPLE 4 (DELETE COLUMN STAT):
-------------------------------

BEGIN 
 dbms_stats.delete_column_stats('SH', 'SALES', 'PROD_ID'); 
END; 
/

OR
exec DBMS_STATS.DROP_EXTENDED_STATS ( 'SH' ,'SALES', '(PROD_ID,CUST_ID)');  

 - Auto Column Groups Detection:
   Step1: Seed Column Usage
    begin
    dbms_stats.seed_col_usage(null,null,300); -- 5 minutes system workload  
    -- exec dbms_stats.seed_col_usage('TunSet_TEST','SYSTEM',3600); ---tuning set workload -max 2 Hours
    end;   
     /
  step2: See column usage report for one or All tables
  select dbms_stats.report_col_usage('EMP','CUSTOMERS') from dual; 
  OR 
  select dbms_stats.report_col_usage('EMP',null) from dual;  -- all shcemas tables
  
  Step3: Create recomended extended statistics
  select dbms_stats.create_extended_stats('SCOTT','EMP') from dual ;  --one table
  select dbms_stats.create_extended_stats('SCOT',null) From dual ;   -- all schema's table 
  
  Step 3: Re-gather Statistics
  exec dbms_stats.gather_table_stats(null,'CUSTOMERS')

to allow SQL plan directives to create column groups automatically 12c:
exec dbms_stats.set_global_prefs ('AUTO_STAT_EXTENSIONS', 'ON');  


- Expression Statistics:

DECLARE
  l_cg_name VARCHAR2(30);
BEGIN
  -- Explicitly created.
  l_cg_name := DBMS_STATS.create_extended_stats(ownname   => 'SCOTT',tabname   => 'EMP',extension => '(LOWER(ENAME))');
  -- Implicitly created.
  DBMS_STATS.gather_table_stats('SCOTT','EMP',method_opt => 'for columns (upper(ename))');
END;
/

SELECT extension_name, extension
FROM   dba_stat_extensions
WHERE  table_name = 'EMP';

select e.extension col_group,
       t.num_distinct,
       t.histogram
from   dba_stat_extensions e
       join dba_tab_col_statistics t on e.extension_name=t.column_name
and    t.table_name = 'EMP';



****************
See stat report:
****************

SELECT column_name, num_distinct, histogram FROM   dba_tab_col_statistics  WHERE  table_name = 'SALES';

-----
TIPS:
-----
Rather than specifying the METHOD_OPT parameter in the statistics gathering command it is highly recommended that you specify any non-default value 
for the METHOD_OPT via DBMS_STATS.SET_TABLE_PREFS(so you it will apply it implicitly .

BEGIN
 dbms_stats.Set_table_prefs('SH', 'SALES', 'METHOD_OPT', -
 'FOR ALL COLUMNS SIZE 254 FOR COLUMNS SIZE 1 PROD_ID');
END;
/

**************************
HISTOGRAM TYPES
**************************
QUERY DBA_TAB_HISTOGRAMS:
ENDPOINT_VALUE : Represents the highest value in the bucket. 
ENDPOINT_NUMBER: Represents the cumulative frequency.
ENDPOINT_REPEAT_COUNT: Number of time highest value in the bucket was repeated.

I-Height-Balanced Histograms (Legacy-(Pre-12c))  NDV>254
--------------------------
* Height-balanced histogram, column values are divided into buckets so that each bucket contains approximately the same number of rows. 
  It is created when the NDV is greater than n(254).
In Oracle database 12c, height-balanced histograms are only created if sampling is explicitly used during statistics collection. If there is no explicit sampling,
 Oracle will perform a full table scan and build a hybrid histogram, or possibly a top frequency histogram depending on the circumstances.

II-Frequency Histograms                      NDV<=254
------------------------
Created most likely when the NDV is less than n(254).Each distinct column value corresponds to a single bucket of the histogram.Because each value has its own 
dedicated bucket, some buckets may have many values, whereas others have few.. (e.i 8).
If a small number of values occupies most of the rows, then creating a frequency histogram on this small set of values is useful even when the NDV 
is greater than n.+>254  (top frequency histogram )

TOP Frequency Histogram : Criteria      POPULAR NDV <=254
1-The data set has more than n distinct values.
2-The percentage of rows occupied by the top n frequent values is equal to or greater than threshold p, where p is (1-(1/n))*100.
3-The estimate_percent parameter is set to AUTO_SAMPLE_SIZE in the DBMS_STATS statistics gathering procedure.

Example :
Table contains 9990 rows that are randomly assigned values 1-9, so there are approximately 1100 rows for each value. 
The remaining 10 rows each have a unique value (9991 to 10000). 
The METHOD_OPT parameter is used to limit the bucket size to 10 during the statistics creation. 
EXEC DBMS_STATS.gather_table_stats(USER, 'TAB1', method_opt => 'FOR COLUMNS RECORD_TYPE SIZE 10');

SELECT (LAG(endpoint_value, 1, 0) OVER (ORDER BY endpoint_value)+1) || '-' || endpoint_value AS range,
       endpoint_value - (LAG(endpoint_value, 1, 0) OVER (ORDER BY endpoint_value)+1) + 1 AS vals_in_range,
       endpoint_number - LAG(endpoint_number, 1, 0) OVER (ORDER BY endpoint_value) AS frequency
FROM   user_tab_histograms
WHERE  table_name  = 'TAB1'
AND    column_name = 'RECORD_TYPE'
ORDER BY endpoint_value;

Table displaying the range, number of values represented and frequency associated with each bucket. 

RANGE                VALS_IN_RANGE  FREQUENCY
-------------------- ------------- ----------
1-1                              1       1136
2-2                              1       1068
3-3                              1       1062
4-4                              1       1138
5-5                              1       1088
6-6                              1       1109
7-7                              1       1119
8-8                              1       1123
9-9                              1       1147
10-10000                      9991          1  --- Single bucket for less popular 10 last unique values (9991 to 10000)

NOTE : But the less popular values are grouped into a single bucked with an artificially low frequency.

III- Hybrid Histograms (12c)                    
------------------------
Combination of frequency and height-balanced histograms used in place of height-balanced histograms.A single endpoint value cannot span buckets.
stores highest value + its frequency in the bucket as well as popularity of other endpoints.
Example :
Table contains 5000 rows  randomly assigned values 1-99 (50 rows for each popular value). The remaining 5000 rows each have a unique value.
TAB1(id,record_type,description)  
-- Query table referencing skewed column record_type to trigger -- histogram creation during next stats gathering.

COLUMN_ID COLUMN_NAME          HISTOGRAM
---------- -------------------- ---------------
         1 ID                   NONE
         2 RECORD_TYPE          HYBRID
         3 DESCRIPTION          NONE
         
ENDPOINT_VALUE : Represents the highest value in the bucket. 
ENDPOINT_NUMBER: Represents the cumulative frequency.
ENDPOINT_REPEAT_COUNT: Number of times the highest value in the bucket was repeated
Table displaying the range, number of values represented and frequency associated with each bucket + ENDPOINT_REPEAT_COUNT .
SELECT (LAG(endpoint_value, 1, 0) OVER (ORDER BY endpoint_value)+1) || '-' || endpoint_value AS range,
       endpoint_value - (LAG(endpoint_value, 1, 0) OVER (ORDER BY endpoint_value)+1) + 1 AS vals_in_range,
       endpoint_number - LAG(endpoint_number, 1, 0) OVER (ORDER BY endpoint_value) AS frequency,
       endpoint_repeat_count
FROM   user_tab_histograms
WHERE  table_name  = 'TAB1'
AND    column_name = 'RECORD_TYPE'
ORDER BY endpoint_value;

RANGE                VALS_IN_RANGE  FREQUENCY ENDPOINT_REPEAT_COUNT
-------------------- ------------- ---------- ---------------------
1-1                              1         54                    54 --Popular
10-10                            1         41                    41 --Popular
11-11                            1         61                    61 --Popular
...
RANGE                VALS_IN_RANGE  FREQUENCY ENDPOINT_REPEAT_COUNT
-------------------- ------------- ---------- ---------------------
100-163                         64         32                     1 --unpopular
164-227                         64         32                     1

Buckets with popular & single value the ENDPOINT_REPEAT_COUNT matches the frequency.
The combination of ENDPOINT_REPEAT_COUNT + range of values in the bucket allow the optimizer to calculate the density of the values in the bucket, 
which allows a greater level of precision while calculating the cardinality.


Views to Query:
--

select COLUMN_NAME,ENDPOINT_NUMBER,ENDPOINT_VALUE,ENDPOINT_ACTUAL_VALUE  from DBA_HISTOGRAMS where column_name ='DAT_SUBS' and 
table_name='CMC_CONTRACTS_OPENED';

COLUMN_NAME          ENDPOINT_NUMBER ENDPOINT_VALUE
-------------------- --------------- --------------
DAT_SUBS                           0        2444416
DAT_SUBS                           1        2445221
DAT_SUBS                           2        2445313
DAT_SUBS                           3        2445377
DAT_SUBS                           4        2445487
DAT_SUBS                           5        2445548
DAT_SUBS                           6        2445611
DAT_SUBS                           7        2445620
DAT_SUBS                           8        2445634

hf53es@AACMTA.ING.BE> select COLUMN_NAME,NUM_BUCKETS,HISTOGRAM,NUM_DISTINCT,LOW_VALUE,HIGH_VALUE,density  from DBA_TAB_COL_STATISTICS where column_name ='DAT_SUBS' and table_name='CMC_CONTRACTS_OPENED';

COLUMN_NAME     NUM_BUCKETS HISTOGRAM       NUM_DISTINCT LOW_VALUE                                                HIGH_VALUE
--------------- ----------- --------------- ------------ ---------------------------------------------------------------- ----------------------------------------------------------------
DAT_SUBS                254 HEIGHT BALANCED         4786 77B40619010101                                           7871030D010101


FORMULAS :
- DENSITY: Density provides selectivity estimates for: equijoin + equality precdicate
  The density is expressed as a decimal number between 0 and 1. 
Values close to 1 indicate that this column is unselective
Values close to 0 indicate that this column is highly selective  ---needs index

Density = Number of non-popular values         
         ---------------------------- 
              total number of values 


- CARDINALITY:
 . Cardinality refers to the uniqueness of data values contained in a particular column (attribute) of a database table . PK column = cardinality=Total nbr of rows 
 . Number of rows retrieved for a certain step in the execution plan
The lower the cardinality = the more duplicated elements in a column. A column with the lowest possible cardinality would have the same value for every row.
           literal not popular     E[card] = density * num_rows;
                                   cardinality = selectivity * total number of rows.
- SELECTIVITY: /Popular Value 

Selectivity = number of rows satisfying a condition (cardinality) 
              ---------------------------------------       
                     total number of rows

Selectivity = Number of end points spanned by this value 
              ------------------------------------------ 
                   total number of end points 

high density =low selectivity=low cardinality  ; low density=high selectivity=high cardinality; 


===================================== 
1- Clustering factor vs ROW MOVEMENT
=====================================
- Index clustering factor is a measure of how many I/Os the database would perform if it were to read every row in that table via the index in index order. 
   If the rows of a table on disk are sorted in about the same order as the index keys, the database will perform a minimum number of I/Os on the table to read the entire table via the index.
   That is because the next row needed from an index key would likely be the next row in the table block as well.
- If table and an index key are in the same order, clustering factor = near the number of blocks in the leaftable (efficient index scan for large table scan)  
- If the data is randomly scattered, clustering factor = near the number of rows in the table, and given that the number of rows in a table is an order of magnitude more than the number of blocks (inefficient index scan for large table scan)  
TABLE BLOCKS  ROWS/BLOCK  IDX CLUSTERING FACTOR  I/O per 200 rows
------------ ------------ ---------------------  -----------------
     100         100            100                2
     100         100            10,000

The leaf blocks of an index store the indexed values as well as the ROWIDs to which they point. If the ROWIDs point to different TABLE blocks during the scan, clustering factor is incremented (this is done for the entire index).

=====================================
BIND PEEKING
=====================================

- When bind peeking is turned off and I have a query like "select * where date >= :d1 and date <:d2", Oracle doesn't peek at the value of :d1 and :d2. It just makes its best guess and estimates the row count.  "good enough" estimate.
- If bind peeking is turned on, Oracle looks at the value of :d1 and d:2 and then examines the statistics including the low/high values for the index on the date column. If the values of :d1 and :d2 are outside of the range given in the low/high values then it estimates a row count of 1.
  all date out of statistic high low range will have a cardinality of 1(bad estimateif stat is expired). 
==================
DYNAMIC SAMPLING
===================
Level	     	                    When Dynamic Sampling will be used                                                                                   Sample size (blocks)
-------- -------------------------------------------------------------------------------------------------------------------------------------------- -------------------- 
0	 Switches off dynamic sampling	N/A
1	 At least one non-partitioned table in the statement has no statistics	                                                                              32
2        (default) One or more tables in the statement have no statistics	                                                                              64
3	 Any statement that meets level 2 criteria and any statement that has one or more expressions used in the where clause predicates e.g.                64
         Where substr(CUSTLASTNAME,1,3) or Where a + b =5	                                                                                               
4	 Any statement that meets level 3 criteria and any statement that has complex predicates. An OR or AND operator between multiple predicates on the    64
         same table	
5	 Any statement that meets level 4 criteria	                                                                                                      128
6	 Any statement that meets level 4 criteria	                                                                                                      256
7	 Any statement that meets level 4 criteria	                                                                                                      512
8	 Any statement that meets level 4 criteria	                                                                                                      1024
9	 Any statement that meets level 4 criteria	                                               	                                                       4086
10	 All statements	All Blocks 


The sampling levels are as follows if the dynamic sampling level used is from a cursor hint or from the OPTIMIZER_DYNAMIC_SAMPLING initialization parameter:

 

Level 0:     Do not use dynamic sampling.
Level 1:     Sample all tables that have not been analyzed if the following criteria are met: (1) there is at least 1 unanalyzed table in the query; (2) this unanalyzed table is joined to another table or appears in a subquery or non-mergeable view; (3) this unanalyzed table has no indexes; (4) this unanalyzed table has more blocks than the number of blocks that would be used for dynamic sampling of this table. The number of blocks sampled is the default number of dynamic sampling blocks (32).
Level 2:     Apply dynamic sampling to all unanalyzed tables. The number of blocks sampled is two times the default number of dynamic sampling blocks.
Level 3:     Apply dynamic sampling to all tables that meet Level 2 criteria, plus all tables for which standard selectivity estimation used a guess for some predicate that is a potential dynamic sampling predicate. The number of blocks sampled is the default number of dynamic sampling blocks. For unanalyzed tables, the number of blocks sampled is two times the default number of dynamic sampling blocks.
Level 4:     Apply dynamic sampling to all tables that meet Level 3 criteria, plus all tables that have single-table predicates that reference 2 or more columns. The number of blocks sampled is the default number of dynamic sampling blocks. For unanalyzed tables, the number of blocks sampled is two times the default number of dynamic sampling blocks.
Levels 5, 6, 7, 8, and 9: Apply dynamic sampling to all tables that meet the previous level criteria using 2, 4, 8, 32, or 128 times the default number of dynamic sampling blocks respectively.
Level 10: Apply dynamic sampling to all tables that meet the Level 9 criteria using all blocks in the table.

====================================
 TABLE ACCESS BY INDEX ROWID BATCHED
====================================

The BATCHED access shown in Step 1 means that the database retrieves a few row ids from the index, and then attempts to access rows in block order to improve the clustering and 
reduce the number of times that the database must access a block.

Consider a below example of the (simplified) index

+-------------+------------------+
| index value | block nbr-rowid  |
+-------------+------------------+
|      1      |   015-000123     |
|      2      |   034-000527     |
|      3      |   088-000285     |
|      4      |   015-000889     |
|      5      |   088-000632     |
........
In the batched method oracle retrieves a few entries from the index, then first sorts them by the number of block, then process entries in the order determined by number of blocks:
retrieves block 15, then retrieves rows 015-000123 and 015-000889 from this block
retrieves block 34, then retrieves row 034-000527 from this block
retrieves block 88, then retrieves rows 088-000285 and 088-000632 from this block 
conclusion 3 block access instead of 5
