Add new resources :

srvctl add database -d oracle -o /u01/app/oracle/product/11.2.0/db_1
srvctl add listener -l LISTENER1 -p TCP:1521 -o /u01/app/oracle/product/11.2.0/db_1
srvctl add service -db dbcrm -service crmbatch -role PHYSICAL_STANDBY


srvctl stop home -oraclehome /u01/app/oracle/product/12.1.0/dbhome_1 -statefile /usr1/or_state  [-stopoption stop_options] [-force]
stop and disable oracle restart:
-------------------------------
crsctl disable has
crsctl stop has
---
crsctl enable has
crsctl start has

srvctl start home -oraclehome /u01/app/oracle/product/12.1.0/dbhome_1 -statefile /usr1/or_state (copy past previous value on stop action)

srvctl setenv {asm|database|listener} options
srvctl unsetenv {asm|database|listener} options
srvctl getenv {database|listener|asm} options
srvctl config object options    srvctl config database -db orcl
srvctl modify object options
example: 
srvctl setenv database -db dbcrm -envs "NLS_LANG=AMERICAN_AMERICA.AL32UTF8, AIXTHREAD_SCOPE=S"


++++++++
Listener
++++++++
#srvctl stop listener
#srvctl start listener
#srvctl config listener -l listener
#srvctl setenv listener -l LISTENER -T TNS_ADMIN=$TNS_ADMIN C:\APP\ORACLE\product\12.1.0.2\db_1\network\admin
#srvctl getenv listener -l listener
 
1. To check status and configurations
----------------------------------
Nodeapps:
srvctl status nodeapps -n nodename
srvctl config nodeapps -n nodename

ASM:
srvctl status asm -n nodename
srvctl config asm -n nodename

Database:
srvctl status database -d dbname
srvctl config database -d dbname (shows instances name, node and oracle home)

Instance:
srvctl status instance -d dbname -i instancename

Services:
srvctl status service -d dbname

2. To start and stop instances
-----------------------------
In a terminal window as the oracle OS user, start the database with the command
srvctl start database -d orcl 
srvctl start instance -d dbname -i instancename
srvctl stop instance -d dbname -i instancename

- To start, stop and manage services
srvctl status service -d dbname
srvctl config service -d dbname
srvctl start service -d dbname -s servicename
srvctl stop service -d dbname -s servicename
srvctl relocate service -d dbname -s servicename -i instancename -t newinstancename [-f]

- To Start a rac database (order: nodeapps – asm – database)
srvctl start nodeapps -n nodename
srvctl start asm -n nodename
srvctl start database -d dbname
options are: srvctl start database -d dbname -o open | -o mount | -o nomount

-To stop a rac database (order: database – asm – nodeapps)
srvctl stop database -d dbname -o immediate
options are: srvctl stop database -d dbname -o normal | -o transactional | -o immediate | -o abort

-To stop asm
 srvctl stop asm -n nodename
options are: srvctl stop asm -n nodename -o immediate

-To stop node
srvctl stop nodeapps -n nodename



+++++++++++++
ASM diskgroup
+++++++++++++
srvctl remove diskgroup -g diskgroup_name [-n node_list] [-f]
srvctl remove diskgroup -g DATA -f

srvctl start diskgroup -g diskgroup_name [-n node_list]
srvctl start diskgroup -g DATA -n node1,node2

srvctl stop diskgroup -g diskgroup_name [-n node_list] [-f]
srvctl stop diskgroup -g FRA
srvctl stop diskgroup -g FRA -n node1,node2 -f

srvctl status diskgroup -g diskgroup_name [-n node_list] [-a]
srvctl status diskgroup -g DATA -n node1,node2 -a

srvctl enable diskgroup -g diskgroup_name [-n node_list]
srvctl enable diskgroup -g DATA -n node1,node2

srvctl disable diskgroup -g diskgroup_name [-n node_list]
srvctl disable diskgroup -g FRA -n node1, node2

-------------------------------------------------------------
add                         // Adds a component to the Oracle Restart configuration.

config                      // Displays the Oracle Restart configuration for a component.

disable                  Disables management by Oracle Restart for a component.

downgrade                 Downgrades the configuration of a database and its services from its current version to the specified lower version.

enable                Reenables management by Oracle Restart for a component.

getenv                   Displays environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener.

modify                  Modifies the Oracle Restart configuration for a component.

remove                   Removes a component from the Oracle Restart configuration.

setenv                   Sets environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener.

start                    Starts the specified component.

status                    Displays the running status of the specified component.

stop                    Stops the specified component.

unsetenv                Unsets environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener.

update                   Updates the running database to switch to the specified startup option.

upgrade                  Upgrades the resources types and resources from an older version to a newer version.


  (SID_DESC =(GLOBAL_DBNAME = MTLDB_DGMGRL.medisolution)
     (ORACLE_HOME =C:\APP\ORACLE\product\12.1.0.2\grid)(SID_NAME = mtldb))
     
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++     
SERVER POOL SWITCH TO POLICY MANAGED DATABASE FROM DBA MANAGED:
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> http://www.hhutzler.de/blog/convert-an-admin-managed-rac-database-to-policy-managed/
http://db.geeksinsight.com/2013/01/13/11gr2-rac-server-pools-what-they-are/


[grid@london1 ~]$ srvctl config database -d rac_db
Database unique name: RAC_DB
Database name: RAC_DB
Oracle home: /u01/app/oracle/product/12.1.0.2/db_1
Oracle user: oracle
Spfile: +DATA/RAC_DB/PARAMETERFILE/spfile.275.975538943
Password file: +DATA/RAC_DB/PASSWORD/pwdrac_db.284.975537953
Domain: evilcorp.com
Start options: open
Stop options: immediate
Database role: PRIMARY
Management policy: AUTOMATIC
Server pools:
Disk Groups: FRA,DATA
Mount point paths:
Services:
Type: RAC
Start concurrency:
Stop concurrency:
OSDBA group: dba
OSOPER group: oper
Database instances: RACDB1,RACDB2
Configured nodes: london1,london2
Database is administrator managed

- check current server pool config 

[grid@london1 ~]$ srvctl status srvpool -a /serverpool -p 
Server pool name: Free
Active servers count: 0
Active server names: 
Server pool name: Generic
Active servers count: 2
Active server names: london1,london2
NAME=london1 STATE=ONLINE
NAME=london1 STATE=ONLINE



- Stop database  
---------------- 
[grid@london1 ~]$ srvctl stop database -d RACDB

- Create Pool and Add RAC database to pool 
-------------------------------------------
[grid@london1 ~]$ srvctl add srvpool -g Sp1 -l 1 -u 2   

-l: refers to Minimum size of the server pool            -u: refers to Maximum suze if the server pool


- Run as user Oracle :
[grid@london1 ~]$ srvctl modify database -d RAC_DB -g Sp1

- restart Database // error :

[grid@london1 ~]$ srvctl start database -d rac_db
  PRCR-1079 : Failed to start resource ora.rac_db.db
  CRS-2643: The server pool(s) where resource 'ora.rac_db.db' could run have no servers

- Remove category and add servers 
[grid@london1 ~]$ srvctl modify srvpool -serverpool sp1  -servers  "london1,london2" -verbose
[grid@london1 ~]$ srvctl config srvpool -serverpool Sp1
Server pool name: TopPriority
Importance: 5, Min: 1, Max: 2
Category: 
Candidate server names: london1,london2

- Verify Database Status and Pool Status after changes :

[grid@london1 ~]$ srvctl status srvpool -a
Server pool name: Generic
Active servers count: 2
Active server names: london1,london2
NAME=london1 STATE=ONLINE
NAME=london2 STATE=ONLINE
Server pool name: Sp1
Active servers count: 0
Active server names: 

--> Now both servers are assigned to our sp1 pool 

[grid@london1 ~]$ srvctl start  database -db rac_db
- check pool status
------------------------
[grid@london1 ~]$ srvctl config database -d rac_db
Database unique name: RAC_DB
Database name: RAC_DB
Oracle home: /u01/app/oracle/product/12.1.0.2/db_1
Oracle user: oracle
Spfile: +DATA/RAC_DB/PARAMETERFILE/spfile.275.975538943
Password file: +DATA/RAC_DB/PASSWORD/pwdrac_db.284.975537953
Domain: evilcorp.com
Start options: open
Stop options: immediate
Database role: PRIMARY
Management policy: AUTOMATIC
Server pools: Sp1
Disk Groups: FRA,DATA
Mount point paths:
Services:
Type: RAC
Start concurrency:
Stop concurrency:
OSDBA group: dba
OSOPER group: oper
Database instances: RACDB1,RACDB2
Configured nodes: london1,london2
Database is policy managed


--  create a service “all” that should run in sp1 (serverpool) on all nodes.

[grid@london1 ~]$ srvctl add service –d orcladm –s all –g sp1 –c uniform …

--- create a service “one” that should run in sp1(serverpool) on only one node

[grid@london1 ~]$ srvctl add service –d orcladm –s all –g sp1 –c singleton ..


++++++++++++++++++++++++++++
Some other notes to DBA,
++++++++++++++++++++++++++++
SIDs are DYNAMIC

- DBA scripts may have to be adjusted
- Environment variables settings in profiles will have to check the current sid
- Directories for LOG files will change over restarts

“Pin” Nodes

[grid@london1 ~]$  crsctl pin css -n london1
- Forces Oracle Clusterware to maintain the same
- Node number when restarted (which maintains SID) Automatically done on upgrades
- Required when running pre-11g Release 2 versions in the cluster
- On upgrade, the nodes will be “pinned”









==================================
 CRSCTL Comande line
==================================

#crsctl stat res ora.racdb.db -t

#crs_stat -p 
# srvctl start instance -d racdb -i  racdb2
  
Review the OSWatcher / Exawatcher top output and the messages file for the down node.
Either:                                 or 

# crsctl stop crs -f             srvctl stop asm -n exaddb01
# crsctl start crs               srvctl start asm -n exaddb01

#$GRID_HOME/bin/crs_stat -t
#$GRID_HOME/bin/crsctl stat res -t -init
#$GRID_HOME/bin/crsctl stop res ora.mdnsd -init
#$GRID_HOME/bin/crsctl stop res ora.evmd -init
#$GRID_HOME/bin/crsctl stop res ora.gpnpd -init 
#$GRID_HOME/bin/crsctl stop res ora.gipcd -init -f
#$GRID_HOME/bin/crsctl stop res ora.oraagent -init
#$GRID_HOME/bin/crsctl query css votedisk
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   8777ca1e7eeb4f87bf04be5872a8164e (/dev/asm-disk1) [DATA]